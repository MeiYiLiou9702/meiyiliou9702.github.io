{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0609_報告用",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFqXcAT27rW7",
        "colab_type": "text"
      },
      "source": [
        "# 主題： 音樂曲風辨識\n",
        "### 成員：地理碩二 曹宇鈞、地理碩一 林子鈞、地理四 劉玫宜\n",
        "\n",
        "\n",
        "#### 專題動機：\n",
        "\n",
        "\n",
        "        音樂豐富了我們的生活，不管是百無聊賴時的精神慰藉，或是深夜獨自一人的心靈雞湯，不同風格的音樂總是能帶給我們許多不同的情緒。然而現在的音樂類型越趨多元與融合，辨識音樂風格本身並不是件容易的事情。\n",
        "        近日盤據美國告示牌排行榜由Lil Nas X演唱的Old town road就產生了這首歌該被歸類在鄉村音樂或是嘻哈音樂的爭論。因此我們想到，如果能利用AI的方式，對音樂進行分類，或許會是件相當有趣的事。\n",
        "        在手邊現有的資源中，有許多的音樂資料庫，而Youtube為了方便影音工作者進行影音工作，蒐集了大量的開放樂曲資料，而這也成為了我們這個專案能夠執行的契機。\n",
        "\n",
        "\n",
        "#### 內容說明：\n",
        "我們使用Youtube創作者工作室提供的音樂庫資料，作為進行曲風辨識的聲音素材。  <br/>\n",
        "分類方面並不是本次專題的重點，因此我們直接沿用Youtube上現有的風格類別做為判斷依據。(當然後續原始碼釋出以後，使用者可以依照自己喜歡的分類喜好重新定義，並執行編碼)  <br/>\n",
        "由於本專案資料量較大，且需要較好的電腦效能，故執行環境我們完全移植到Google Colab上面執行，環境設定會在稍後進行說明 。  <br/>\n",
        "<br/>\n",
        "#### 工作階段：\n",
        "本專案的工作階段可以分成：「專案構想討論、資料處理、模型訓練、報告書面整理」四個階段。  <br/>\n",
        "\n",
        "![流程圖](https://imgur.com/oXcEdgO.jpg)  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "在**資料處理**部分，可以簡易分成三個階段  \n",
        "\n",
        "#### 階段一：從Youtube Audio資料庫中撈取資料\n",
        "1. 透過python selenium撰寫爬蟲爬取相關音訊資訊(json格式)  \n",
        "\n",
        "2. 透過pandas讀取json檔案，以requests進行請求下載聲音檔案，並依照曲風進行資料夾分類。  \n",
        "\n",
        "#### 階段二：將音樂資料預處理，轉換成model可直接讀取的np.array\n",
        "本階段的預處理中，牽涉到音樂資料要處理成什麼格式。  \n",
        "這部分我們參考了已經做過音樂分類的論文，發現多數人在進行音訊處理會使用 「librosa」這個package。 <br/>\n",
        "在 librosa 當中有直接可以對音訊進行傅立葉轉換的函數，以及將傅立葉轉換之後的音訊資料，取出梅爾頻譜進行分析的函數。\n",
        "\n",
        "#### 階段三：將np.array另存，並轉成可在model中使用的格式<br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBO4OPv5gjov",
        "colab_type": "text"
      },
      "source": [
        "# Google Drive環境設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiqMJEnXhRL_",
        "colab_type": "text"
      },
      "source": [
        "## 將個人google drive設定為Colab的工作區"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWUHBx_n9ecV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "ed4b5e32-2f0c-437f-99cf-9b166d8c3d56"
      },
      "source": [
        "#專案開始只要執行一遍就好(之後同一個帳號不用再執行資料夾授權)\n",
        "#這個程式碼會要求個人google 帳戶的SDK的權限。\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 133872 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.18-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.18-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.18-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pad6gnLyhXeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Linux的指令\n",
        "#本指令也只需要執行一次就好\n",
        "!mkdir -p drive #新增一個連結google drive資料的目錄\n",
        "!google-drive-ocamlfuse drive  #連結到google drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-rIjnYThXUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7296286d-14dd-433f-e439-3be748668695"
      },
      "source": [
        "# 查看當前工作位置與目錄清單\n",
        "import os\n",
        "print('Current work directory is : ',os.getcwd())\n",
        "print('Directory list : ',os.listdir())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current work directory is :  /content\n",
            "Directory list :  ['.config', 'drive', 'adc.json', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eD-pREyhXNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0b962d7-a501-4718-b53a-8a0f4847993c"
      },
      "source": [
        "#路徑設定\n",
        "dirpath = \"drive/AI_math\"\n",
        "if os.path.isdir(dirpath):\n",
        "  print(\"existed\")\n",
        "  os.chdir(dirpath) #設定工作路徑\n",
        "else:\n",
        "  print(\"Unexisted\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "existed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHJDlfcRhg-U",
        "colab_type": "text"
      },
      "source": [
        "# Youtube檔案下載"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2DV5AfQhrHd",
        "colab_type": "text"
      },
      "source": [
        "## 使用的套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QADrplBAhXGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys, os, io, time\n",
        "import requests, json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bIyQQXAhtgx",
        "colab_type": "text"
      },
      "source": [
        "### 將音訊分類至各個風格的資料夾\n",
        "* 整合json\n",
        "* 依照曲風獲取download_url\n",
        "* 下載至指定資料夾\n",
        "\n",
        "\n",
        "![Imgur](https://i.imgur.com/29uDMrD.png)<br/>\n",
        "![Imgur](https://i.imgur.com/uc44D0w.png) <br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MssnnkZJhtun",
        "colab_type": "text"
      },
      "source": [
        "#### json 整合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq7PgUMNh6C4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_folder = os.getcwd() + \"\\\\YouTube-Audio-Library\\\\json\"  #放置json檔案的位置\n",
        "print(json_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx6WMqDvh59n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 把所有的json檔案整合成同一個json\n",
        "rows_list = [] #儲存以下for迴圈的變數\n",
        "for _, dirnames, filenames in os.walk(json_folder): #資料夾裡面的檔案逐項讀取\n",
        "    # get all files in this folder\n",
        "    for filename in filenames: #\n",
        "        if(filename == 'all_data.json'):\n",
        "            continue\n",
        "            \n",
        "        # read json with pandas\n",
        "        df = pd.read_json(json_folder + \"\\\\\" + filename, encoding='utf-8')\n",
        "        \n",
        "        # audio information\n",
        "        audios = df['tracks']\n",
        "        for audio in audios:\n",
        "            # append audio to list\n",
        "            rows_list.append(audio)\n",
        "        \n",
        "        # create dataframe from list\n",
        "        audios_df = pd.DataFrame(rows_list) #最後輸出的DataFrame(儲存所有的json的資料表)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stpOWUPbh51M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DataFrame輸出成json檔案\n",
        "audios_df.to_json(json_folder + \"\\\\all_data.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWvrn0qchudN",
        "colab_type": "text"
      },
      "source": [
        "#### 讀取剛剛整合好的json檔案，依照曲風獲得download_url，以及依照曲風創造資料夾\n",
        "\n",
        "> 缩进块\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yur8jIvphW6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#資料讀取\n",
        "audios_df = pd.read_json('all_data.json', encoding='utf-8')\n",
        "\n",
        "#獲得曲風的屬性\n",
        "genre = audios_df['genre']\n",
        "\n",
        "# 計算每個曲風裡面有多少首歌\n",
        "audios_df.groupby(['genre'],as_index=False)['genre'].agg({'count':'count'})\n",
        "result = audios_df.groupby(\"genre\")\n",
        "result.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zwtn-q5ifWY",
        "colab_type": "text"
      },
      "source": [
        "##### [支線]分類名稱略有差異→合併差異資料\n",
        "* Country & Folk\n",
        "* Country Folk\n",
        "* Country and Folk\n",
        "---\n",
        "* Dance & Electronic\n",
        "* Electronic\n",
        "---\n",
        "* Hip Hop & Rap\n",
        "* Hip Hop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JNTPYfYi9Di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clearGenreClass(df, genre):\n",
        "    result = df[df['genre'] == genre]\n",
        "    df = df.drop(df.index[result.index.tolist()])\n",
        "    \n",
        "    return df\n",
        "  \n",
        "audios_df = clearGenreClass(audios_df, 'None')\n",
        "audios_df = clearGenreClass(audios_df, 'World')\n",
        "\n",
        "#輸出看一下結果\n",
        "audios_df.groupby(['genre'],as_index=False)['genre'].agg({'count':'count'})\n",
        "\n",
        "#檔案輸出(格式：.json)\n",
        "audios_df.to_json(json_folder + \"\\\\all_data.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31_9H_efifTq",
        "colab_type": "text"
      },
      "source": [
        "#### 依照曲風新增資料夾"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC6Q3WgOi-5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#依照genre裡面的屬性新增list\n",
        "dir_list = group['genre'].tolist()\n",
        "\n",
        "\n",
        "#function ：在path底下創造新的資料夾\n",
        "def createDirectory(path):\n",
        "    base_dir = os.getcwd()\n",
        "\n",
        "    try:  \n",
        "        os.makedirs(path)\n",
        "    except OSError:  \n",
        "        print (\"Creation of the directory %s failed\" % path)\n",
        "    else:  \n",
        "        print (\"Successfully created the directory %s\" % path)      \n",
        "\n",
        "    return base_dir + \"\\\\\" + path\n",
        " \n",
        "\n",
        " #根據dir_list創造資料夾路徑\n",
        "for d in dir_list:\n",
        "    createDirectory(\"genre/\" + d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxR7V61IiekH",
        "colab_type": "text"
      },
      "source": [
        "#### 檔案下載"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWDc-f8jjhaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = os.getcwd() + \"\\\\genre\\\\\" #要下載的東西儲存的路徑設定到工作區底下的genre資料夾裡面\n",
        "# print(base_path)\n",
        "#資料下載的loop\n",
        "for url, genre, title in zip(audios_df['download_url'], audios_df['genre'], audios_df['title']):\n",
        "    filename = base_path + genre + \"\\\\\" + title + \".mp3\" #檔案預計載入的路徑+檔名\n",
        "    print(filename)\n",
        "    #避免重複下載，檢查檔案是否存在\n",
        "    if os.path.isfile(filename):\n",
        "        print('existed')\n",
        "    else:       \n",
        "        # requests 向url請求檔案下在\n",
        "        try:\n",
        "          r = requests.get(url)\n",
        "          with open(filename, 'wb') as f:  #寫入檔案\n",
        "              f.write(r.content)\n",
        "        except:\n",
        "          print(\"request fail...\") #如果寫入失敗的話\n",
        "          with open('/path/to/file', 'r') as f:\n",
        "            print(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEZ8ChmijlCG",
        "colab_type": "text"
      },
      "source": [
        "# 資料讀取\n",
        "### 設計說明\n",
        "* 本部分與後續的模型設計，程式碼與結構參考自：  <br/>\n",
        " Hguimaraes (2018), [REPO] Music Genre classification on GTZAN dataset using CNNs. Github.  <br/>\n",
        " 網址：https://github.com/Hguimaraes/gtzan.keras [2019.05.17]  <br/>\n",
        "* LibROSA  package使用，參照 ：LibROSA — librosa 0.6.3 documentation  <br/>\n",
        "網址：https://librosa.github.io/librosa/ [2019.05.17] <br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhCInyWkjqZT",
        "colab_type": "text"
      },
      "source": [
        "##需要的套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_saKqs-ejkpQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e6b5b3ff-cbc1-4576-c3e3-d10ced5ac359"
      },
      "source": [
        "#import basic package\n",
        "%matplotlib inline\n",
        "%env KERAS_BACKED=tensorflow\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
        "\n",
        "import keras\n",
        "import h5py\n",
        "import librosa\n",
        "import librosa.display\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from ipywidgets import interact\n",
        "import math\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: KERAS_BACKED=tensorflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhJzIKxwjzzW",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ep3IvwVj9N0",
        "colab_type": "text"
      },
      "source": [
        "### 將音訊陣列利用短時序傅立葉轉換，轉換成梅爾頻譜的格式\n",
        "梅爾刻度根據一個轉換公式，在人耳可以聽見的範圍，從1000Hz，音量大於40分貝為基準，然後每500Hz去給定一個音高，根據不同頻率變化的幅度(amplitudes)轉換為梅爾頻譜後，再經過對數處理將數字差距拉大就能形成不同曲風的特徵值。<br/>\n",
        "赫茲與梅爾頻譜的公式:<br/>\n",
        "$m = 2595log_{10}\\left ( 1+\\frac{f}{700} \\right )$<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4TkKIjVjkgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_melspectrogram(songs, n_fft = 1024, hop_length = 512):\n",
        "    # Transformation function\n",
        "    melspec = lambda x: librosa.feature.melspectrogram(x, n_fft = n_fft,hop_length = hop_length)[:,:,np.newaxis]\n",
        "\n",
        "    # map transformation of input songs to melspectrogram using log-scale\n",
        "    tsongs = map(melspec, songs)\n",
        "    return np.array(list(tsongs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AMoouOhkL24",
        "colab_type": "text"
      },
      "source": [
        "### 歌曲分割 (用於增加樣本數)\n",
        "本函數只取每首歌前30秒，每3秒分為一個音檔，有1.5秒與前段重複。song_sample本次設定為660000，若要產生更多歌曲樣本，請更改song_sample的數字。<br/>\n",
        "\n",
        "採樣率:每秒從連續訊號中提取並組成離散訊號的取樣個數，以赫茲（Hz）來表示。<br/>\n",
        "\n",
        "本次取用的音訊採樣率為22050Hz(此為一般無線電廣播之採樣率)<br/>\n",
        "\n",
        "計算公式:<br/>\n",
        "一個音樂檔案所包含的聲波長度<br/>\n",
        "$$22050(Hz)*30(sec) = 661500(Hz)$$<br/>\n",
        "而函式設定3秒切割一個音檔，剩餘的音訊長度不足以成為一個音檔，因此song_sample取660000Hz<br/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKDe19uZjkbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitsongs(X, y, window = 0.1, overlap = 0.5):\n",
        "    # Empty lists to hold our results\n",
        "    temp_X = []\n",
        "    temp_y = []\n",
        "\n",
        "    # Get the input song array size\n",
        "    xshape = X.shape[0]\n",
        "    chunk = int(xshape*window)\n",
        "    offset = int(chunk*(1.-overlap))\n",
        "    \n",
        "    # Split the song and create new ones on windows\n",
        "    spsong = [X[i:i+chunk] for i in range(0, xshape - chunk + offset, offset)]\n",
        "    for s in spsong:\n",
        "        temp_X.append(s)\n",
        "        temp_y.append(y)\n",
        "\n",
        "    return np.array(temp_X), np.array(temp_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os9Q-Hcrr7g5",
        "colab_type": "text"
      },
      "source": [
        "### 訓練資料預處理的檔案讀取函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPwymH2Mr8LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(audios_df,data_list,np_ar1,np_ar2,read_list2,src_dir, genres, song_samples, spec_format, debug = True):    \n",
        "    # Empty array of dicts with the processed features from all files\n",
        "    arr_specs = []\n",
        "    arr_genres = []\n",
        "    read_list = []\n",
        "\n",
        "    # Read files from the folders\n",
        "    for x,_ in genres.items():\n",
        "        folder = src_dir + x\n",
        "        \n",
        "        for root, subdirs, files in os.walk(folder):\n",
        "            for file,idx in zip(files,range(0,len(files))):\n",
        "                # Read the audio file\n",
        "                file_name = folder + \"/\" + file\n",
        "                #檢查重複\n",
        "                if sum(data_list==file_name) >= 1:\n",
        "                  print(file_name,'已經存在,跳過!!')\n",
        "                  continue\n",
        "                  \n",
        "                else:\n",
        "                  # Debug process\n",
        "                  if debug:\n",
        "                    print(idx,\"Reading file: {}\".format(file_name))\n",
        "                  #防悲劇機制\n",
        "                  t = ()\n",
        "                  t = audios_df['len'][audios_df['title'] == str(file).replace(\".mp3\",\"\")]\n",
        "                  t = pd.DataFrame(t)\n",
        "                  if len(t) > 1: #避免名字重複發生慘劇\n",
        "                    for g,idx in zip(t.index,range(0,len(t),1)):\n",
        "                      gg = audios_df['genre'][g]\n",
        "                      if gg == x:\n",
        "                        t = (float(t.reset_index()['len'][idx]))\n",
        "                        break\n",
        "                      else:\n",
        "                        continue\n",
        "                  else:\n",
        "                        t = float(t['len'])\n",
        "                  #Is audio over 30s                  \n",
        "                  if t < 30:\n",
        "                    print('不到30秒')\n",
        "                    continue\n",
        "                    \n",
        "                  else:\n",
        "                    signal, sr = librosa.load(file_name)\n",
        "                    signal = signal[:song_samples]\n",
        "                    print('load_done')\n",
        "                    \n",
        "                  # Convert to dataset of spectograms/melspectograms\n",
        "                  signals, y = splitsongs(signal, genres[x])                \n",
        "                  # Convert to \"spec\" representation\n",
        "                  specs = spec_format(signals)\n",
        "                  # Save files\n",
        "                  arr_genres.extend(y)\n",
        "                  arr_specs.extend(specs)\n",
        "                  read_list.append(file_name)\n",
        "                  #儲存中間過程的檔案，怕colab關起來\n",
        "\n",
        "                  np.save(str(np_ar1), arr_specs) #music_strongth\n",
        "                  np.save(str(np_ar2), arr_genres) #music class \n",
        "                  np.save(str(read_list2), read_list)\n",
        "                \n",
        "    return np.array(arr_specs), np.array(arr_genres)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIEpjAfoxeSA",
        "colab_type": "text"
      },
      "source": [
        "## 檔案讀取與在模型裡面實作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWsblaHwJAet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.load('all_signal_list0_13.npy')\n",
        "y = np.load('all_cat_list.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VmEal94JHAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = X[:313728]\n",
        "sr=22050\n",
        "melspec = librosa.feature.melspectrogram(x, sr, n_fft=1024, hop_length=512, n_mels=128)\n",
        "logmelspec = librosa.power_to_db(melspec)\n",
        "plt.figure(figsize=(16,8))\n",
        "librosa.display.specshow(logmelspec, x_axis='time', y_axis='mel')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krt_AtTdJQcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.reshape(79097,128,129,1)\n",
        "X.shape,y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIZ2YJS_JQho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = to_categorical(y)\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h84KN-TgJQfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teeXVOhuJaHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Histogram for train and test \n",
        "values, count = np.unique(np.argmax(y_train, axis=1), return_counts=True)\n",
        "plt.bar(values, count)\n",
        "\n",
        "values, count = np.unique(np.argmax(y_test, axis=1), return_counts=True)\n",
        "plt.bar(values, count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2J6RyihJaQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Definition\n",
        "input_shape = X_train[0].shape\n",
        "num_genres = 14\n",
        "\n",
        "model = Sequential()\n",
        "# Conv Block 1\n",
        "model.add(Conv2D(16, kernel_size=(3, 3), strides=(1, 1),\n",
        "                 activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# Conv Block 2\n",
        "model.add(Conv2D(32, (3, 3), strides=(1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# Conv Block 3\n",
        "model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# Conv Block 4\n",
        "model.add(Conv2D(128, (3, 3), strides=(1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Conv Block 5\n",
        "model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# MLP\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_genres, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO4gI73DJkLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(X_train, y_train,\n",
        "          batch_size=1000,\n",
        "          epochs=5,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "# score = model.evaluate(X_test, y_test, verbose=0)\n",
        "# print(\"val_loss = {:.3f} and val_acc = {:.3f}\".format(score[0], score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dxs90nGJkV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}